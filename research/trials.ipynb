{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#to change dir. to working folder\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Imports pdf readers, since we are working with pdf file    \n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data from PDF File\n",
    "def load_pdf_file(data):\n",
    "    #Take data directory and only loads the \"pdf\" tags\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use method above and set equal to extracted_data\n",
    "extracted_data = load_pdf_file(data = 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Chunking Operation: Which divdes our large dataset,\n",
    "#into smaller manageable datasets\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text chunks 265\n"
     ]
    }
   ],
   "source": [
    "#Executing above method\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of text chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Embedding model\n",
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/msmarco-MiniLM-L-6-v3')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karth\\anaconda3\\envs\\footballchat\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\karth\\.cache\\huggingface\\hub\\models--sentence-transformers--msmarco-MiniLM-L-6-v3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the above embeddings to create vector embeddings\n",
    "#Which are numerical representations of data that can be used for ML processing\n",
    "#Pinecone is a db that allows you to quickly manage and search datasets with predefined embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_7PAbgS_55bDeai2Mmn87jTphnC74CVrpYL2goV7477hd7tnEZaZpthjhjJtrmGGdvMHQjM\")\n",
    "\n",
    "index_name = \"footballchat\"\n",
    "\n",
    "pc.create_index(\n",
    "    name = index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "os.environ['PINECONE_API_KEY'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we embed each chunk and upsert the embeddings into Pinecone Index\n",
    "#Converts all embeddings into vector embeddings and stores in pinecone db\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    index_name = index_name,\n",
    "    embedding= embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Existing index, this is how we search now off of pinecone db\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is a VEER?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8f2f49cf-e265-42bf-aa64-1835c11c5661', metadata={'page': 53.0, 'source': 'Data\\\\footballxos-spread-offense-playbook.pdf'}, page_content='VEER\\nVEER RIGHT vs 4-3\\nVEER RIGHT vs 4-3 Under \\nMinnesota Vikings – Hug Self as if Cold \\nVEER RIGHT vs 4-4 Stack \\nVEER RIGHT vs 4-4\\nVEER RIGHT vs 5-2\\nVEER RIGHT vs 3-4\\nVEER RIGHT vs 3-5\\nVEER RIGHT vs Bear'),\n",
       " Document(id='545d81f5-d2f9-4848-9891-da7a51e91e66', metadata={'page': 52.0, 'source': 'Data\\\\footballxos-spread-offense-playbook.pdf'}, page_content='VEER\\nVEER RIGHT vs 4-3\\nVEER RIGHT vs 4-3 Under \\nMinnesota Vikings – Hug Self as if Cold \\nVEER RIGHT vs 4-4 Stack \\nVEER RIGHT vs 4-4\\nVEER RIGHT vs 5-2\\nVEER RIGHT vs 3-4\\nVEER RIGHT vs 3-5\\nVEER RIGHT vs Bear'),\n",
       " Document(id='29ce8fce-0b2a-485a-8477-cd03b463f486', metadata={'page': 51.0, 'source': 'Data\\\\footballxos-spread-offense-playbook.pdf'}, page_content='VEER\\nQB \\nSecure snap moving towards the LOS, place ball in the gut of the RB with your eyes directly on the handoff \\nkey, if the handoff key crashes down, pull the ball and read the block of the slot receiver \\nF\\nMust get a pre-snap read to see aiming point (outside leg of first down lineman inside of the handoff key), on \\nsnap, shuffle towards QB and give a loose pocket for the ball, attack aiming point \\nX')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview of response, now we process it with LLM\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process of preparing the llm with prompts to process our db\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer\"\n",
    "    \"the question. If you dont know the answer, say that you \"\n",
    "    \"don't know. Use Three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    {\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The process of RAG(Retrieval Augmented Generation) is the process of optimizing a model by\n",
    "#first referring to a designated knowledge base\n",
    "#So were telling the llm to first based its answer off of the base we made above\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Must get a pre-snap read to see aiming point (outside leg of first down lineman inside of the handoff key), on \n",
      "snap, shuffle towards QB and give a loose pocket for the ball, attack aiming point\n",
      "\n",
      "VEER is a type of offensive play in American football where the quarterback secures the snap and hands the ball off to the running back while reading the block of the slot receiver. It is commonly used against defensive formations such as 4-3, 4-4, 5-2, 3-4, 3-5, and Bear. The QB and X positions must get a pre-snap read to determine the aiming point and then execute the play accordingly.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is VEER?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "One possible play to run against two high safeties is the \"Smash-In\" play. In this play, the QB's first read is to the receiver running a dig route, who pushes vertical to 10 yards before breaking straight across the field. The second read is to the receiver running a corner route, who nods and breaks at 10 yards towards the front pylon. The third read is to the receiver running a go route, aiming for 2 yards outside the hash at 22 yards. The QB should expect the ball to be thrown immediately on the Smash-In route. The offensive line should also be prepared to block for a potential run play, with the BST pulling through the hole created by the PSG. This play is particularly effective against a three-man front, but can also be run against a four-man front.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Give me an example of a play to run against two high safeties\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "footballchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
